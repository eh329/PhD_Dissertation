{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of this paper:\n",
    "#### https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, models, losses\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from skimage.io import imread_collection\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, bins = (4, 6, 3)):\n",
    "    \"\"\"\n",
    "    Takes an image and resuces its dimensionality.\n",
    "    This function was written as an alternative to using PCA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: The merged microcopy image in the folder\n",
    "    bins: Required for histogram and measuring pixel intesitiy\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    A flattened image with one dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins,\n",
    "                       [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(path):\n",
    "    \"\"\"\n",
    "    Reads merged images, transform them to HSV images and then reduces their dimensionality\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: Path to the training images with / in the end \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    HSV images with reduced dimensionality\n",
    "    \"\"\"\n",
    "    \n",
    "    final_path = path + \"*.*\" \n",
    "    colored_imgs = [cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2HSV) for img in glob.glob(final_path)]\n",
    "    return np.array(list(map(normalize_img, colored_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_preparation(path)\n",
    "model = IsolationForest(n_estimators = 100, contamination = 0.01,\n",
    "                       random_state = 42)\n",
    "\n",
    "model.fit(data)\n",
    "scores = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open(\"OneClassIF.pkl\", \"wb\")\n",
    "pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(index = np.arange(1, len(scores), 1), columns = [\"Outlier\", \"Normal\"])\n",
    "\n",
    "for index, value in enumerate(scores, start = 1):\n",
    "    if value == 1:\n",
    "        result.loc[index] = [0, 1]\n",
    "        \n",
    "    else:\n",
    "        result.loc[index] = [-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(path, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of One Class SVM\n",
    "## Source: https://link.springer.com/article/10.1007/s42979-020-00418-2#Sec10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: traditional features\n",
    "def extract_traditional_features(img):\n",
    "    gray = rgb2gray(img)\n",
    "    h = hog(gray, pixels_per_cell = (16,16), cells_per_block = (2,2), feature_vector = True)\n",
    "    return h\n",
    "\n",
    "# Option B: deep features via pre-trained VGG16\n",
    "base_vgg = VGG16(weights = 'imagenet', include_top = False, input_shape = (img_h, img_w, 3))\n",
    "feat_model = Model(inputs=base_vgg.input, outputs = base_vgg.get_layer('block3_conv3').output)\n",
    "\n",
    "def extract_deep_features(img):\n",
    "    img = img[np.newaxis]  # batch dimension\n",
    "    feats = feat_model.predict(img)\n",
    "    return feats.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on Set 1\n",
    "feats = [extract_deep_features(img) for img in X_train]\n",
    "X_feats = np.stack(feats)\n",
    "\n",
    "models = {\n",
    "    'ocsvm': OneClassSVM(kernel = 'rbf', gamma = 'auto', nu = 0.1).fit(X_feats),\n",
    "    'lof': LocalOutlierFactor(n_neighbors = 20, novelty = True).fit(X_feats),\n",
    "    'iforest': IsolationForest(contamination = 0.05).fit(X_feats),\n",
    "    'cov': EllipticEnvelope(contamination = 0.05).fit(X_feats),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(x):\n",
    "    votes = [int(m.predict([x])[0] == -1) for m in models.values()]\n",
    "    return sum(votes) >= 2  # at least 2 models flag → anomaly\n",
    "\n",
    "# Process Set 2\n",
    "feat_test = np.stack([extract_deep_features(img) for img in X_test])\n",
    "anomaly_labels = [ensemble_predict(x) for x in feat_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(feat_test):\n",
    "    if anomaly_labels[i]:\n",
    "        dists = [euclidean(x, db) for db in X_feats]\n",
    "        closest = X_feats[np.argmin(dists)]\n",
    "        # Compute feature-wise difference\n",
    "        diff = np.abs(x - closest)\n",
    "        # Identify top contributing features\n",
    "        top_indices = np.argsort(diff)[-5:]\n",
    "        print(f\"Image {i} anomaly – top diff feature dims: {top_indices}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Gaussian Mixture Modeling (GMM)\n",
    "## Source: https://www.mdpi.com/1999-4893/16/4/195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Extract features via pre-trained VGG16 block3_conv3\n",
    "base_vgg = VGG16(weights = 'imagenet', include_top=False)\n",
    "feat_model = Model(inputs = base_vgg.input, outputs = base_vgg.get_layer('block3_conv3').output)\n",
    "\n",
    "def extract_features(img):\n",
    "    img = img[np.newaxis]\n",
    "    return feat_model.predict(img).reshape(-1)\n",
    "\n",
    "X_train_feats = np.stack([extract_features(img) for img in X_train])\n",
    "X_test_feats = np.stack([extract_features(img) for img in X_test])\n",
    "\n",
    "# 2️⃣ Fit initial GMM on normal features\n",
    "n_components = 5  # adjust based on data\n",
    "gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=0)\n",
    "gmm.fit(X_train_feats)\n",
    "\n",
    "# 3️⃣ Compute entropy of cluster assignments to guide noise init\n",
    "probs = gmm.predict_proba(X_train_feats)  # shape (n_samples, n_components)\n",
    "sample_entropy = entropy(probs.T)         # per-sample entropy\n",
    "noise_data = X_train_feats[np.argsort(sample_entropy)[-int(0.05*len(sample_entropy)):]]\n",
    "\n",
    "# 4️⃣ Add a dedicated noise component initialized from high-entropy data\n",
    "X_aug = np.vstack([X_train_feats, noise_data])\n",
    "gmm2 = GaussianMixture(n_components=n_components+1, covariance_type='full', random_state=0)\n",
    "gmm2.fit(X_aug)\n",
    "\n",
    "# 5️⃣ Anomaly detection: test samples with low likelihood cluster\n",
    "log_probs = gmm2.score_samples(X_test_feats)\n",
    "threshold = np.percentile(gmm2.score_samples(X_train_feats), 5)\n",
    "anomalies = log_probs < threshold\n",
    "\n",
    "print(f\"Threshold log-likelihood: {threshold:.2f}\")\n",
    "print(f\"Detected {anomalies.sum()} anomalies out of {len(X_test_feats)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Deep Perceptual Autoencoders (DPA)\n",
    "## Source: https://arxiv.org/pdf/2006.13265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Set 1 (normal training images)\n",
    "train_paths = [...]  # List of 384 paths to normal images\n",
    "X_train = np.array([cv2.imread(img).astype('float32') / 65535.0 for img in train_paths])  # Normalize 16-bit to [0, 1]\n",
    "\n",
    "# Load Set 2 (experimental images: control + anomalies)\n",
    "test_paths = [...]  # List of 384 paths to experimental images\n",
    "X_test = np.array([cv2.imread(img).astype('float32') / 65535.0 for img in test_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Set 1 (normal training images)\n",
    "train_paths = [...]  # List of 384 paths to normal images\n",
    "X_train = np.array([cv2.imread(img).astype('float32') / 65535.0 for img in train_paths])  # Normalize 16-bit to [0, 1]\n",
    "\n",
    "# Load Set 2 (experimental images: control + anomalies)\n",
    "test_paths = [...]  # List of 384 paths to experimental images\n",
    "X_test = np.array([cv2.imread(img).astype('float32') / 65535.0 for img in test_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "input_img = layers.Input(shape=(X_train.shape[1], X_train.shape[2], 3))  # BGR input\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoder\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = models.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 for perceptual loss\n",
    "vgg = VGG16(weights = 'imagenet', include_top = False, input_shape=(X_train.shape[1], X_train.shape[2], 3))\n",
    "vgg.trainable = False\n",
    "perceptual_model = models.Model(inputs = vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    mse = losses.mse(y_true, y_pred)  # Pixel-wise error\n",
    "    true_features = perceptual_model(y_true)\n",
    "    pred_features = perceptual_model(y_pred)\n",
    "    perc_loss = losses.mse(true_features, pred_features)  # Feature-wise error\n",
    "    return mse + 0.1 * perc_loss  # Combined loss\n",
    "\n",
    "autoencoder.compile(optimizer = 'adam', loss=perceptual_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_train, X_train,  # Input = Target (self-supervised)\n",
    "    epochs = 50,\n",
    "    batch_size = 8,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reconstructions and errors\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "errors = np.mean(np.abs(X_test - reconstructions), axis=(1, 2, 3))  # Per-image error\n",
    "\n",
    "# Flag anomalies (top 5% highest errors)\n",
    "threshold = np.percentile(errors, 95)\n",
    "anomalies = errors > threshold\n",
    "\n",
    "# Print results\n",
    "print(f\"Anomaly threshold: {threshold:.4f}\")\n",
    "for i in range(len(X_test)):\n",
    "    if anomalies[i]:\n",
    "        print(f\"Image {i}: ANOMALY (Score: {errors[i]:.4f})\")\n",
    "    else:\n",
    "        print(f\"Image {i}: Normal (Score: {errors[i]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 5 most anomalous images\n",
    "anomaly_indices = np.argsort(errors)[-5:]\n",
    "for idx in anomaly_indices:\n",
    "    plt.figure()\n",
    "    plt.imshow(X_test[idx])\n",
    "    plt.title(f\"Anomaly Score: {errors[idx]:.4f}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
