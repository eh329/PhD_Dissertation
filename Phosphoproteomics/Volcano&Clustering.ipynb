{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd695b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import KMeans, k_means\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from plotly import graph_objects\n",
    "from plotly import express\n",
    "from plotly import figure_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "podo_data = pd.read_excel(\"NewHeader.xlsx\", header = [0, 1, 2])\n",
    "podo_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = podo_data.copy()\n",
    "print(\"dataset:\", podo_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ce8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in podo_df.columns:\n",
    "    print(col[0], \"/-/\", col[1], \"/-/\", col[2], \" - & Number of NaN:\", podo_df[col[0]][col[1]].isnull().sum()[0], \"- & dtype:\", podo_df[col].dtypes)\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Accession\"][\"Protein names\"][\"Total_Inf_Accession_Protein.names\"].notna()]\n",
    "df = df[df[\"Phospho ID Metrics\"][\"Phospho Sites\"][\"Phos_Inf_Phospho.ID.Metrics_Phosphosites\"].notna()]\n",
    "df = df[df[\"No Header\"][\"Phosphopeptide Present\"][\"Both_Phosphopeptide.Present\"] == True]\n",
    "df = df[df[\"Database\"][\"Human\"][\"Total_Database_Human\"] == True]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in _df.columns:\n",
    "    print(col[0], \"/-/\", col[1], \"/-/\", col[2], \" - & Number of NaN:\", podo_df[col[0]][col[1]].isnull().sum()[0], \"- & dtype:\", podo_df[col].dtypes)\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6318655",
   "metadata": {},
   "source": [
    "## Volcano Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b152bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volcano_dataset_prep(index_col, t_test, log_fc, fdr_col, heatmap_data = None):\n",
    "    \"\"\"\n",
    "    Separates the columns requred for making a volcano plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index_col: Pandas series holding index values\n",
    "    t_test: Pandas series holding t test values\n",
    "    log_fc: Pandas series holding log fc values\n",
    "    fdr_col: Pandas series holding fdr values\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "     A new pandas dataframe for volcano plotheatmap_data = Optional, pandas dataframe that can be used to create heatmap later\n",
    "    \"\"\"\n",
    "    dataset = pd.concat((index_col, t_test, log_fc, fdr_col, heatmap_data), axis = 1)\n",
    "    dataset = dataset.set_index(\"Total_Inf_Accession_Protein.names\")\n",
    "    dataset = dataset.dropna()\n",
    "    return dataset\n",
    "\n",
    "def x_y_axes(data):\n",
    "    \"\"\"\n",
    "    Prepares x and y axes for volcano plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas dataframe prepared by volcano_dataset_prep\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    x_values: List, from LogFC column, to be the values on x axis\n",
    "    y_value: List, negative log 10 of t_test column values, to be the values on the y axis\n",
    "    hover: List, containing the names of the proteins, to be used to identify the name of the values on the plot \n",
    "    \"\"\"\n",
    "    x_col = [x for x in data.columns if \"LogFC\" in x][0]\n",
    "    y_col = [y for y in data.columns if \"Test\" in y][0]\n",
    "    x_values = data[x_col].values\n",
    "    y_values = np.log10(data[y_col].values) * -1\n",
    "    hover = list(data.index)\n",
    "    return x_values, y_values, hover\n",
    "\n",
    "def volcano_plot(x_val, y_val, hover_list, title):\n",
    "    \"\"\"\n",
    "    Creates annotated volcano plot from p values and FDR values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_values: List, from LogFC column, to be the values on x axis\n",
    "    y_value: List, negative log 10 of t_test column values, to be the values on the y axis\n",
    "    hover: List, containing the names of the proteins, to be used to identify the name of the values on the plot\n",
    "    title: String, used for the title of the plot\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    A volcano plot separating proteins by biological and statistical significane\n",
    "    \n",
    "    \"\"\"\n",
    "    x_minimum = min(x_val)\n",
    "    x_maximum = max(x_val)\n",
    "    y_minimum = min(y_val)\n",
    "    y_maximum = max(y_val)\n",
    "    p_val_cut = np.log10(0.05) * -1\n",
    "    \n",
    "    fig = graph_objects.Figure()\n",
    "    image = graph_objects.Scatter(x = x_val, y = y_val, mode = 'markers', hovertext = hover_list)\n",
    "    fig.add_trace(image)\n",
    "    fig.add_shape(type = 'line', x0 = -1, y0 = y_minimum - 0.2, x1 = -1, y1 = y_maximum + 0.2, line = dict(color = 'Red',), xref = 'x', yref = 'y')\n",
    "    fig.add_shape(type = 'line', x0 = 1, y0 = y_minimum - 0.2, x1 = 1, y1 = y_maximum + 0.2, line = dict(color = 'Red',), xref = 'x', yref = 'y')\n",
    "    fig.add_shape(type = 'line', x0 = x_minimum - 0.1, y0 = p_val_cut, x1 = x_maximum + 0.1, y1 = p_val_cut, line = dict(color = 'Red',), xref = 'x', yref = 'y')\n",
    "    fig.update_layout(title = title, xaxis_title = \"Log2 Fold Change\", yaxis_title = \"P-Value (-Log10)\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f25673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the parts required for calculations\n",
    "\n",
    "first_ge_df = ge_df[[\"No Header\", \"Accession\" ,\"Stats - C3a/C\", \"Stats - C4a/C\", \"Phospho Adjusted Log2 Normalised Abundanxe\"]]\n",
    "first_ge_df = first_ge_df[first_ge_df[\"No Header\"][\"Phosphopeptide Present\"][\"Both_Phosphopeptide.Present\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead58d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter NaN values\n",
    "first_ge = first_ge_df.dropna()\n",
    "\n",
    "# Make Protein namse the index \n",
    "index = first_ge[\"Accession\"][\"Protein names\"].reset_index(drop = True)\n",
    "logfc = first_ge[\"Stats\"][\"Adjusted Phosphopeptide Stats LogFC\"].apply(pd.to_numeric, args = ('coerce',)).astype(float).reset_index(drop = True)\n",
    "ttest = first_ge[\"Stats\"][\"Adjusted Phosphopeptide Stats T Test\"].apply(pd.to_numeric, args = ('coerce',)).astype(float).reset_index(drop = True)\n",
    "fdr = first_ge[\"Stats\"][\"Adjusted Phosphopeptide Stats FDR\"].apply(pd.to_numeric, args = ('coerce',)).astype(float).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e169407",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_dataset = volcano_dataset_prep(index, c3_ttest, c3_logfc, c3_fdr).dropna()\n",
    "x, y, hover = x_y_axes(c3_dataset)\n",
    "volcano_plot(x, y, hover, \"C3/C Adjusted Phospho Abundance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_dataset.rename(columns = {\"Phos_Stats.Adj_C3a.C_T.Test\": \"T Test\", \n",
    "                                                          \"Phos_Stats.Adj_LogFC\": \"LogFC\",\n",
    "                                                         \"Phos_Stats.Adj_FDR\": \"FDR\"}, inplace = True)\n",
    "c3_dataset.index.rename(\"Protein Names\", inplace = True)\n",
    "\n",
    "c3_dataset[\"P Value\"] = np.log10(c3_dataset[\"T Test\"]) * -1\n",
    "p = np.log10(0.05) * -1\n",
    "volcano_list = c3_dataset[((c3_dataset[\"LogFC\"] > 1) | (c3_dataset[\"LogFC\"] < -1)) & (c3_dataset[\"P Value\"] >= p)]\n",
    "volcano_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_c3_dataset = volcano_dataset_prep(index, c3_ttest, c3_logfc, c3_fdr, heatmap_part)\n",
    "heatmap_c3_dataset = heatmap_c3_dataset.rename(columns = {\"Phos_Stats.Adj_T.Test\": \"T Test\", \n",
    "                                                          \"Phos_Stats.Adj_LogFC\": \"LogFC\",\n",
    "                                                         \"Phos_Stats.Adj_FDR\": \"FDR\"})\n",
    "p_val = np.log10(heatmap_c3_dataset[\"T Test\"]) * -1\n",
    "heatmap_c3_dataset.insert(loc = 3, column = \"P Value\", value = p_val)\n",
    "heatmap_c3_dataset.index.rename(\"Protein Names\", inplace = True)\n",
    "heatmap_c3_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dendrogram with heatmap\n",
    "\n",
    "dendogram = heatmap_c3_dataset[['sample1', 'sample2',\n",
    "       'sample3', 'sample4',\n",
    "       'sample5', 'sample6']]\n",
    "\n",
    "dendo = dendogram.T\n",
    "labels = dendogram.columns\n",
    "\n",
    "fig = figure_factory.create_dendrogram(dendo, orientation = 'bottom', labels = labels)\n",
    "for i in range(len(fig['data'])):\n",
    "    fig['data'][i]['yaxis'] = 'y2'\n",
    "    \n",
    "dendro_side = figure_factory.create_dendrogram(dendo, orientation = 'right')\n",
    "for i in range(len(dendro_side['data'])):\n",
    "    dendro_side['data'][i]['xaxis'] = 'x2'\n",
    "\n",
    "\n",
    "for data in dendro_side['data']:\n",
    "    fig.add_trace(data)\n",
    "\n",
    "dendro_leaves = dendro_side['layout']['yaxis']['ticktext']\n",
    "dendro_leaves = list(map(int, dendro_leaves))\n",
    "data_dist = pdist(dendo)\n",
    "heat_data = squareform(data_dist)\n",
    "heat_data = heat_data[dendro_leaves, :]\n",
    "heat_data = heat_data[:, dendro_leaves]\n",
    "\n",
    "\n",
    "heatmap = [\n",
    "    graph_objects.Heatmap(\n",
    "        x = dendro_leaves,\n",
    "        y = dendro_leaves,\n",
    "        z = heat_data,\n",
    "        colorscale = 'Reds'\n",
    "    )\n",
    "]\n",
    "\n",
    "heatmap[0]['x'] = fig['layout']['xaxis']['tickvals']\n",
    "heatmap[0]['y'] = dendro_side['layout']['yaxis']['tickvals']\n",
    "\n",
    "# Add Heatmap Data to Figure\n",
    "for data in heatmap:\n",
    "    fig.add_trace(data)\n",
    "    \n",
    "fig.update_layout({'width':800, 'height':800,\n",
    "                         'showlegend':False, 'hovermode': 'closest',\n",
    "                         })\n",
    "# Edit xaxis\n",
    "fig.update_layout(xaxis={'domain': [.15, 1],\n",
    "                                  'mirror': False,\n",
    "                                  'showgrid': False,\n",
    "                                  'showline': False,\n",
    "                                  'zeroline': False,\n",
    "                                  'ticks':\"\"})\n",
    "# Edit xaxis2\n",
    "fig.update_layout(xaxis2={'domain': [0, .15],\n",
    "                                   'mirror': False,\n",
    "                                   'showgrid': False,\n",
    "                                   'showline': False,\n",
    "                                   'zeroline': False,\n",
    "                                   'showticklabels': False,\n",
    "                                   'ticks':\"\"})\n",
    "\n",
    "# Edit yaxis\n",
    "fig.update_layout(yaxis={'domain': [0, .85],\n",
    "                                  'mirror': False,\n",
    "                                  'showgrid': False,\n",
    "                                  'showline': False,\n",
    "                                  'zeroline': False,\n",
    "                                  'showticklabels': False,\n",
    "                                  'ticks': \"\"\n",
    "                        })\n",
    "# Edit yaxis2\n",
    "fig.update_layout(yaxis2 = {'domain':[.825, .975],\n",
    "                                   'mirror': False,\n",
    "                                   'showgrid': False,\n",
    "                                   'showline': False,\n",
    "                                   'zeroline': False,\n",
    "                                   'showticklabels': False,\n",
    "                                   'ticks':\"\"})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b90071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating correlation analysis table\n",
    "\n",
    "mask = np.triu(np.ones_like(dendogram.corr(), dtype = bool))\n",
    "\n",
    "\n",
    "plt.figure(dpi = 100)\n",
    "sns.set(rc = {'figure.figsize':(5, 5)})\n",
    "plt.title(\"Correlation Analysis\", fontsize = 10)\n",
    "sns.heatmap(dendogram.corr(), mask = mask, cmap = \"viridis\", fmt = \".0%\",\n",
    "            annot = True, linewidths = 0.1, linecolor = \"black\", annot_kws = {\"size\": 10})\n",
    "plt.xticks(rotation = 70, fontsize = 10)\n",
    "plt.yticks(rotation = 0, fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d678268",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_volc_sig = heatmap_c3_dataset[((heatmap_c3_dataset[\"LogFC\"] > 1) | (heatmap_c3_dataset[\"LogFC\"] < -1)) & (heatmap_c3_dataset[\"P Value\"] >= p)]\n",
    "c3_volc_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d9d1e",
   "metadata": {},
   "source": [
    "## Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_indeces = ['sample1', 'sample2',\n",
    "       'sample3', 'sample4',\n",
    "       'sample5', 'sample6']\n",
    "\n",
    "controls = [\"C-1\", \"C-2\", \"C-3\"]\n",
    "treatment1 = [\"T-1.1\", \"T-1.2\", \"T-1.3\"]\n",
    "treatment2 = [\"T-2.1\", \"T-2.2\", \"T-2.3\"]\n",
    "\n",
    "\n",
    "\n",
    "def k_finder(data, max_k = 20):\n",
    "    \"\"\"\n",
    "    Calculates inertia for a specific range of clusters to find the\n",
    "    best number to assign to k in k-means clustering algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas dataframe, data that is ready for cluster analysis\n",
    "    max_k: Int, maximum number of clusters that is going to be tested.\n",
    "           20, by default   \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    A matplotlib figure\n",
    "    \"\"\"\n",
    "    k_num = range(2, max_k)\n",
    "    inertia = []\n",
    "    \n",
    "    for k in k_num:\n",
    "        kmeans = KMeans(n_clusters = k, randoms_state = 69)\n",
    "        km = kmeans.fit(scaled_data.values)\n",
    "        inertia.append(km.inertia_)\n",
    "        \n",
    "    fig, ax = plt.subplots(1, figsize = (15, 6))\n",
    "    xax = np.arange(len(k_num))\n",
    "    ax.plot(xax, inertia)\n",
    "    ax.set_xticks(xax)\n",
    "    ax.set_xticklabels(k_num)\n",
    "    ax.set_yticklabels(np.array(inertia).round(1)[::-1], fontsize = 15)\n",
    "    plt.xlabel(\"Number of Clusters\", fontsize = 20)\n",
    "    plt.ylabel(\"Inertia Score\", fontsize = 20)\n",
    "    plt.title(\"Inertia per K\", fontsize = 20)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def k_cluster(data, cluster_num = 2):\n",
    "    \"\"\"\n",
    "    Accepts the data prepared for clustering and fit the kmenas clustering\n",
    "    algorithm to it\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas dataframe, data that is ready for cluster analysis\n",
    "    cluster_num: Int, best number of cluster. 2, by default\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    kmeans= KMeans(n_clusters = cluster_num, random_state = 69)\n",
    "    predicted = kmeans.fit_predict(scaled_data.values)\n",
    "    un, counts = np.unique(predicted, return_counts = True)\n",
    "    count = counts.reshape(1, cluster_num)\n",
    "    cols = [\"Cluster \" + str(x) for x in range(1, cluster_num + 1)]\n",
    "    return pd.DataFrame(count, columns = cols)\n",
    "\n",
    "\n",
    "def optimized_kcluster(data, n_comp, k_clust):\n",
    "    \"\"\"\n",
    "    Optimazation of K means clustering with PCA\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas datframe, data prepared for clustering analysis\n",
    "    n_comp: Int, the ideal number for principal components provided from best_comp function\n",
    "    k_clust: Int, best number of cluster provided by k_finder function\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Pandas dataframe of optimized k means clustering analysis\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components = n_comp, random_state = 42)\n",
    "    pca_mod = pca.fit_transform(data)\n",
    "    kmean = KMeans(n_clusters = k_clust, random_state = 69)\n",
    "    km = kmean.fit_predict(pca_mod)\n",
    "    un, counts = np.unique(km, return_counts = True)\n",
    "    count = counts.reshape(1, k_clust)\n",
    "    cols = [\"Cluster \" + str(x) for x in range(1, k_clust + 1)]\n",
    "    return pd.DataFrame(count, columns = cols)\n",
    "\n",
    "\n",
    "def best_comp(data):\n",
    "    \"\"\"\n",
    "    Works out what is the ideal number of component for PCA analysis\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas datframe, data prepared for clustering analysis\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    A matplotlib plot\n",
    "    \"\"\"\n",
    "    comp_num = data.shape[1]\n",
    "    pca = PCA(n_components = comp_num, random_state = 42)\n",
    "    pca_mod = pca.fit_transform(data.values)\n",
    "    total_var = sum(pca.explained_variance_)\n",
    "    var_95 = total_var * 0.95\n",
    "    print(f\"Total Variance: {round(total_var, 2)}\")\n",
    "    print()\n",
    "    \n",
    "    values = zip(range(0, comp_num), pca.explained_variance_)\n",
    "    report = pd.DataFrame(values, columns = [\"PCA Components\", \"Explained Variance\"])\n",
    "    print(report)\n",
    "    print()\n",
    "\n",
    "    plt.figure(figsize = (15, 7))\n",
    "    plt.plot(pca.explained_variance_ratio_, linewidth = 2.5, c = \"b\")\n",
    "    plt.xlabel(\"Number of Components\", fontsize = 15)\n",
    "    plt.ylabel(\"Explained Ratio\", fontsize = 15)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def pca_initiation(sub_data, n_comp):\n",
    "    \"\"\"\n",
    "    Accepts data for PCA, scale the data and fits the algorithm to it\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_data: Pandas dataframe required for PCA analysis\n",
    "    n_comp: Int, the ideal number for principal components provided from best_comp function\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    pca_data_final: Numpy array, applied PCA to values from the original dataset \n",
    "    per_var_info: Numpy array, the explained variance of PCA that is calculated as ratio of eigenvalue \n",
    "                  of a articular principal component (eigenvector) with total eigenvalues.\n",
    "    labels: List, labels for components of the analysis to be used for plotting in scree_plot function\n",
    "    \"\"\"\n",
    "    pca_init = PCA(n_components = n_comp, random_state = 42)\n",
    "    pca_data_final = pca_init.fit_transform(sub_data)\n",
    "    per_var_info = np.round(pca_init.explained_variance_ratio_ * 100, decimals = 1)\n",
    "    labels = [\"PC\" + str(x) for x in range(1, len(per_var_info) + 1)]\n",
    "    return pca_data_final, per_var_info, labels\n",
    "\n",
    "\n",
    "def scree_plot(variance, all_labels, save = False, name = None):\n",
    "    \"\"\"\n",
    "    Accpets the PCA data and creats the scree plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    variance: Numpy array, the second result returned from pca_initiation function\n",
    "    all_labels: List, the third result returned from pca_initiation function\n",
    "    save: Boolean, determines whether the scree plot should be saved in the directory or not. \n",
    "          False, by default.\n",
    "    name: String, if the save argument is True, then a name is required to save the image with.\n",
    "          None, by default\n",
    "          \n",
    "    Returns\n",
    "    ---------\n",
    "    A matplotlib image with png format\n",
    "    \"\"\"\n",
    "    if save == False:\n",
    "        plt.figure(figsize = (10, 5))\n",
    "        plt.bar(x = range(1, len(variance) + 1), height = variance, tick_label = all_labels)\n",
    "        plt.ylabel(\"Percentage of Explained Variance\", fontsize = 15)\n",
    "        plt.xlabel(\"Principal Components\", fontsize = 15)\n",
    "        plt.title(\"Scree Plot\")\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        plt.figure(figsize = (10, 5))\n",
    "        plt.bar(x = range(1, len(variance) + 1), height = variance, tick_label = all_labels)\n",
    "        plt.ylabel(\"Percentage of Explained Variance\", fontsize = 15)\n",
    "        plt.xlabel(\"Principal Components\", fontsize = 15)\n",
    "        plt.title(\"Scree Plot\")\n",
    "        plt.savefig(name)\n",
    "        \n",
    "        \n",
    "def pca_result_df(final_pca_df ,all_labels):\n",
    "    \"\"\"\n",
    "    Creates a Pandas dataframe from the data whose values have been transformed with PCA analysis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    final_pca_df: Numpy array, the first result returned from pca_initiation function\n",
    "    all_labels: List, the third result returned from pca_initiation function\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Pandas dataframe with principal components as columns and the name of samples as index\n",
    "    \n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(final_pca_df, \n",
    "             index = [*cs, *c4as],\n",
    "             columns = all_labels)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "        \n",
    "def pca_2d_graph(pca_df_final, per_var_info, title, save = False, name = None):\n",
    "    \"\"\"\n",
    "    Accepts data whose values have been transformed with PCA algorithm and creates\n",
    "    a scatter plot with the first and second principal components of each sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pca_df_final: Pandas dataframe, result of pca_result_df function \n",
    "    per_var_info: Numpy array, the second result returned from pca_initiation function \n",
    "    title: String, title needed for the scatter plot\n",
    "    save: Boolean, saves the plot as a png file if True. False by default\n",
    "    name: String, if save is True, then a name is required for the plot to be saved with\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    A matplotlib plot with png format\n",
    "    \"\"\"\n",
    "    if save == False:\n",
    "        plt.figure(figsize = (7, 7))\n",
    "        plt.scatter(pca_df_final.PC1, pca_df_final.PC2)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"PC1 - {0}%\".format(per_var_info[0]))\n",
    "        plt.ylabel(\"PC2 - {0}%\".format(per_var_info[1]))\n",
    "        plt.plot([0, 0], [min(pca_df_final.PC2) - 3, max(pca_df_final.PC2) + 3], color='green',\n",
    "             linestyle = 'dashed', linewidth = 2)\n",
    "\n",
    "        plt.plot([min(pca_df_final.PC1), max(pca_df_final.PC1)], [0, 0], color='green',\n",
    "             linestyle = 'dashed', linewidth = 2)\n",
    "\n",
    "        for sample in pca_df_final.index:\n",
    "            plt.annotate(sample, (pca_df_final.PC1.loc[sample], pca_df_final.PC2.loc[sample]))\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        plt.figure(figsize = (7, 7))\n",
    "        plt.scatter(pca_df_final.PC1, pca_df_final.PC2)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"PC1 - {0}%\".format(per_var_info[0]))\n",
    "        plt.ylabel(\"PC2 - {0}%\".format(per_var_info[1]))\n",
    "\n",
    "        for sample in pca_df_final.index:\n",
    "            plt.annotate(sample, (pca_df_final.PC1.loc[sample], pca_df_final.PC2.loc[sample]))\n",
    "            \n",
    "        plt.svaefig(name + \".png\")\n",
    "        \n",
    "        \n",
    "def pca_multi_graph(var_ratio, pca_dataframe, pca_data_transformed, dimension, title):\n",
    "    \"\"\"\n",
    "    Creates a correlograph if all the principal components from the PCA analysis\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_ratio: Numpy array, the second result returned from pca_initiation function\n",
    "    pca_dataframe: Pandas dataframe, result of pca_result_df function\n",
    "    pca_data_transformed: Numpy array, the first result returned from pca_initiation function\n",
    "    dimension: Int, length of pca_dataframe \n",
    "    title: String, used as the title of the correlograph\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    An interactive correlograph\n",
    "    \"\"\"\n",
    "    x_y_labels = {\n",
    "    str(i): f\"PC {i + 1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(var_ratio * 100)}\n",
    "    \n",
    "    fig = express.scatter_matrix(\n",
    "        pca_data_transformed,\n",
    "        labels = x_y_labels,\n",
    "        dimensions = range(1, dimension),\n",
    "        color = pca_dataframe.index, width = 1200, height = 1200, title = title)\n",
    "    fig.update_traces(diagonal_visible = False)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
